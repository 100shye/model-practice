{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "arranged-expression",
   "metadata": {},
   "source": [
    "# xgboost로 분류하기 <br>\n",
    "1. 정답 못냈을 경우를 대비해 아무 숫자로나 적은 파일 만들어두고 시작하기 <br>\n",
    "2. early stopping 하면 학습 오차 감소 안하면 stop 가능 <br>\n",
    "n-estimator을 200으로 해둬도 초기 스탑을 50으로 설정하면 50회 반복하는 동안 학습오차 감소 없으면 스탑함\n",
    "\n",
    "### 과적합 제어하는 법\n",
    "1. etq(learning rate임, 0~1)를 낮춘다. eta 낮추면 num_boost_round는 높여야 함 <br>\n",
    "num_boost_round: waek learner 개수\n",
    "2. max_depth값 낮추기 \n",
    "3. min_child_weight 높이기\n",
    "4. gamma값 높이기\n",
    "5. subsample, colsample_bytree 낮추기\n",
    "\n",
    "### 순서\n",
    "1. 데이터 분리하기  -> sklearn, model selection 이런거 있음\n",
    "2. xgboost는 DMatrix로 형태 바꿔서 사용해야함,  split한 train, test 둘다 바꿔주기\n",
    "\n",
    "  \n",
    "https://injo.tistory.com/44"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "hollow-bouquet",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "unique-chest",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 악성종양 0 , 양성은 1\n",
    "df = load_breast_cancer()\n",
    "X = df.data\n",
    "Y = df.target\n",
    "cancer_df = pd.DataFrame(data=X, columns = df.feature_names)\n",
    "cancer_df['target'] =Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "meaningful-bubble",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "455"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# 데이터 분리하기  -> sklearn, model selection 이런거 있음\n",
    "#help(train_test_split)\n",
    "Xtrain, Xtest, ytrain, ytest = train_test_split(X, Y, test_size=0.2)\n",
    "len(Xtrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "brave-growing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function train in module xgboost.training:\n",
      "\n",
      "train(params: Dict[str, Any], dtrain: xgboost.core.DMatrix, num_boost_round: int = 10, *, evals: Union[Sequence[Tuple[xgboost.core.DMatrix, str]], NoneType] = None, obj: Union[Callable[[numpy.ndarray, xgboost.core.DMatrix], Tuple[numpy.ndarray, numpy.ndarray]], NoneType] = None, feval: Union[Callable[[numpy.ndarray, xgboost.core.DMatrix], Tuple[str, float]], NoneType] = None, maximize: Union[bool, NoneType] = None, early_stopping_rounds: Union[int, NoneType] = None, evals_result: Dict[str, Dict[str, Union[List[float], List[Tuple[float, float]]]]] = None, verbose_eval: Union[bool, int, NoneType] = True, xgb_model: Union[str, os.PathLike, xgboost.core.Booster, bytearray, NoneType] = None, callbacks: Union[Sequence[xgboost.callback.TrainingCallback], NoneType] = None, custom_metric: Union[Callable[[numpy.ndarray, xgboost.core.DMatrix], Tuple[str, float]], NoneType] = None) -> xgboost.core.Booster\n",
      "    Train a booster with given parameters.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    params :\n",
      "        Booster params.\n",
      "    dtrain :\n",
      "        Data to be trained.\n",
      "    num_boost_round :\n",
      "        Number of boosting iterations.\n",
      "    evals :\n",
      "        List of validation sets for which metrics will evaluated during training.\n",
      "        Validation metrics will help us track the performance of the model.\n",
      "    obj\n",
      "        Custom objective function.  See :doc:`Custom Objective\n",
      "        </tutorials/custom_metric_obj>` for details.\n",
      "    feval :\n",
      "        .. deprecated:: 1.6.0\n",
      "            Use `custom_metric` instead.\n",
      "    maximize : bool\n",
      "        Whether to maximize feval.\n",
      "    early_stopping_rounds :\n",
      "        Activates early stopping. Validation metric needs to improve at least once in\n",
      "        every **early_stopping_rounds** round(s) to continue training.\n",
      "        Requires at least one item in **evals**.\n",
      "        The method returns the model from the last iteration (not the best one).  Use\n",
      "        custom callback or model slicing if the best model is desired.\n",
      "        If there's more than one item in **evals**, the last entry will be used for early\n",
      "        stopping.\n",
      "        If there's more than one metric in the **eval_metric** parameter given in\n",
      "        **params**, the last metric will be used for early stopping.\n",
      "        If early stopping occurs, the model will have two additional fields:\n",
      "        ``bst.best_score``, ``bst.best_iteration``.\n",
      "    evals_result :\n",
      "        This dictionary stores the evaluation results of all the items in watchlist.\n",
      "    \n",
      "        Example: with a watchlist containing\n",
      "        ``[(dtest,'eval'), (dtrain,'train')]`` and\n",
      "        a parameter containing ``('eval_metric': 'logloss')``,\n",
      "        the **evals_result** returns\n",
      "    \n",
      "        .. code-block:: python\n",
      "    \n",
      "            {'train': {'logloss': ['0.48253', '0.35953']},\n",
      "             'eval': {'logloss': ['0.480385', '0.357756']}}\n",
      "    \n",
      "    verbose_eval :\n",
      "        Requires at least one item in **evals**.\n",
      "        If **verbose_eval** is True then the evaluation metric on the validation set is\n",
      "        printed at each boosting stage.\n",
      "        If **verbose_eval** is an integer then the evaluation metric on the validation set\n",
      "        is printed at every given **verbose_eval** boosting stage. The last boosting stage\n",
      "        / the boosting stage found by using **early_stopping_rounds** is also printed.\n",
      "        Example: with ``verbose_eval=4`` and at least one item in **evals**, an evaluation metric\n",
      "        is printed every 4 boosting stages, instead of every boosting stage.\n",
      "    xgb_model :\n",
      "        Xgb model to be loaded before training (allows training continuation).\n",
      "    callbacks :\n",
      "        List of callback functions that are applied at end of each iteration.\n",
      "        It is possible to use predefined callbacks by using\n",
      "        :ref:`Callback API <callback_api>`.\n",
      "    \n",
      "        .. note::\n",
      "    \n",
      "           States in callback are not preserved during training, which means callback\n",
      "           objects can not be reused for multiple training sessions without\n",
      "           reinitialization or deepcopy.\n",
      "    \n",
      "        .. code-block:: python\n",
      "    \n",
      "            for params in parameters_grid:\n",
      "                # be sure to (re)initialize the callbacks before each run\n",
      "                callbacks = [xgb.callback.LearningRateScheduler(custom_rates)]\n",
      "                xgboost.train(params, Xy, callbacks=callbacks)\n",
      "    \n",
      "    custom_metric:\n",
      "    \n",
      "        .. versionadded 1.6.0\n",
      "    \n",
      "        Custom metric function.  See :doc:`Custom Metric </tutorials/custom_metric_obj>`\n",
      "        for details.\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    Booster : a trained booster model\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import xgboost\n",
    "help(xgboost.train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "affecting-vegetarian",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:31:49] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"early_stoppings\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-logloss:0.61072\teval-logloss:0.61524\n",
      "[1]\ttrain-logloss:0.54286\teval-logloss:0.55123\n",
      "[2]\ttrain-logloss:0.48448\teval-logloss:0.49737\n",
      "[3]\ttrain-logloss:0.43392\teval-logloss:0.44985\n",
      "[4]\ttrain-logloss:0.39056\teval-logloss:0.40978\n",
      "[5]\ttrain-logloss:0.35423\teval-logloss:0.37654\n",
      "[6]\ttrain-logloss:0.32107\teval-logloss:0.34534\n",
      "[7]\ttrain-logloss:0.29157\teval-logloss:0.31888\n",
      "[8]\ttrain-logloss:0.26728\teval-logloss:0.29667\n",
      "[9]\ttrain-logloss:0.24413\teval-logloss:0.27636\n",
      "[10]\ttrain-logloss:0.22396\teval-logloss:0.25670\n",
      "[11]\ttrain-logloss:0.20522\teval-logloss:0.24259\n",
      "[12]\ttrain-logloss:0.18932\teval-logloss:0.22883\n",
      "[13]\ttrain-logloss:0.17487\teval-logloss:0.21498\n",
      "[14]\ttrain-logloss:0.16064\teval-logloss:0.20458\n",
      "[15]\ttrain-logloss:0.14871\teval-logloss:0.19513\n",
      "[16]\ttrain-logloss:0.13795\teval-logloss:0.18745\n",
      "[17]\ttrain-logloss:0.12827\teval-logloss:0.18005\n",
      "[18]\ttrain-logloss:0.11952\teval-logloss:0.17287\n",
      "[19]\ttrain-logloss:0.11123\teval-logloss:0.16843\n",
      "[20]\ttrain-logloss:0.10346\teval-logloss:0.16313\n",
      "[21]\ttrain-logloss:0.09703\teval-logloss:0.15836\n",
      "[22]\ttrain-logloss:0.09106\teval-logloss:0.15311\n",
      "[23]\ttrain-logloss:0.08561\teval-logloss:0.14857\n",
      "[24]\ttrain-logloss:0.08014\teval-logloss:0.14385\n",
      "[25]\ttrain-logloss:0.07528\teval-logloss:0.14175\n",
      "[26]\ttrain-logloss:0.07116\teval-logloss:0.13879\n",
      "[27]\ttrain-logloss:0.06697\teval-logloss:0.13537\n",
      "[28]\ttrain-logloss:0.06335\teval-logloss:0.13481\n",
      "[29]\ttrain-logloss:0.06011\teval-logloss:0.13165\n",
      "[30]\ttrain-logloss:0.05718\teval-logloss:0.12984\n",
      "[31]\ttrain-logloss:0.05454\teval-logloss:0.12814\n",
      "[32]\ttrain-logloss:0.05187\teval-logloss:0.12768\n",
      "[33]\ttrain-logloss:0.04895\teval-logloss:0.12631\n",
      "[34]\ttrain-logloss:0.04680\teval-logloss:0.12641\n",
      "[35]\ttrain-logloss:0.04471\teval-logloss:0.12648\n",
      "[36]\ttrain-logloss:0.04287\teval-logloss:0.12611\n",
      "[37]\ttrain-logloss:0.04109\teval-logloss:0.12629\n",
      "[38]\ttrain-logloss:0.03939\teval-logloss:0.12434\n",
      "[39]\ttrain-logloss:0.03754\teval-logloss:0.12362\n",
      "[40]\ttrain-logloss:0.03604\teval-logloss:0.12484\n",
      "[41]\ttrain-logloss:0.03465\teval-logloss:0.12357\n",
      "[42]\ttrain-logloss:0.03342\teval-logloss:0.12438\n",
      "[43]\ttrain-logloss:0.03210\teval-logloss:0.12432\n",
      "[44]\ttrain-logloss:0.03105\teval-logloss:0.12487\n",
      "[45]\ttrain-logloss:0.02996\teval-logloss:0.12483\n",
      "[46]\ttrain-logloss:0.02887\teval-logloss:0.12506\n",
      "[47]\ttrain-logloss:0.02755\teval-logloss:0.12608\n",
      "[48]\ttrain-logloss:0.02645\teval-logloss:0.12544\n",
      "[49]\ttrain-logloss:0.02568\teval-logloss:0.12574\n",
      "[50]\ttrain-logloss:0.02486\teval-logloss:0.12575\n",
      "[51]\ttrain-logloss:0.02409\teval-logloss:0.12726\n",
      "[52]\ttrain-logloss:0.02314\teval-logloss:0.12839\n",
      "[53]\ttrain-logloss:0.02239\teval-logloss:0.12750\n",
      "[54]\ttrain-logloss:0.02185\teval-logloss:0.12842\n",
      "[55]\ttrain-logloss:0.02125\teval-logloss:0.12857\n",
      "[56]\ttrain-logloss:0.02077\teval-logloss:0.12952\n",
      "[57]\ttrain-logloss:0.02030\teval-logloss:0.12996\n",
      "[58]\ttrain-logloss:0.01972\teval-logloss:0.13076\n",
      "[59]\ttrain-logloss:0.01915\teval-logloss:0.13109\n",
      "[60]\ttrain-logloss:0.01876\teval-logloss:0.13142\n",
      "[61]\ttrain-logloss:0.01831\teval-logloss:0.13045\n",
      "[62]\ttrain-logloss:0.01782\teval-logloss:0.13149\n",
      "[63]\ttrain-logloss:0.01745\teval-logloss:0.13261\n",
      "[64]\ttrain-logloss:0.01702\teval-logloss:0.13334\n",
      "[65]\ttrain-logloss:0.01667\teval-logloss:0.13332\n",
      "[66]\ttrain-logloss:0.01635\teval-logloss:0.13277\n",
      "[67]\ttrain-logloss:0.01604\teval-logloss:0.13271\n",
      "[68]\ttrain-logloss:0.01574\teval-logloss:0.13211\n",
      "[69]\ttrain-logloss:0.01545\teval-logloss:0.13285\n",
      "[70]\ttrain-logloss:0.01517\teval-logloss:0.13222\n",
      "[71]\ttrain-logloss:0.01494\teval-logloss:0.13310\n",
      "[72]\ttrain-logloss:0.01467\teval-logloss:0.13311\n",
      "[73]\ttrain-logloss:0.01443\teval-logloss:0.13357\n",
      "[74]\ttrain-logloss:0.01417\teval-logloss:0.13443\n",
      "[75]\ttrain-logloss:0.01396\teval-logloss:0.13510\n",
      "[76]\ttrain-logloss:0.01369\teval-logloss:0.13560\n",
      "[77]\ttrain-logloss:0.01346\teval-logloss:0.13623\n",
      "[78]\ttrain-logloss:0.01326\teval-logloss:0.13584\n",
      "[79]\ttrain-logloss:0.01305\teval-logloss:0.13638\n",
      "[80]\ttrain-logloss:0.01286\teval-logloss:0.13592\n",
      "[81]\ttrain-logloss:0.01267\teval-logloss:0.13598\n",
      "[82]\ttrain-logloss:0.01250\teval-logloss:0.13704\n",
      "[83]\ttrain-logloss:0.01232\teval-logloss:0.13757\n",
      "[84]\ttrain-logloss:0.01212\teval-logloss:0.13807\n",
      "[85]\ttrain-logloss:0.01195\teval-logloss:0.13803\n",
      "[86]\ttrain-logloss:0.01179\teval-logloss:0.13830\n",
      "[87]\ttrain-logloss:0.01166\teval-logloss:0.13909\n",
      "[88]\ttrain-logloss:0.01152\teval-logloss:0.13898\n",
      "[89]\ttrain-logloss:0.01136\teval-logloss:0.13947\n",
      "[90]\ttrain-logloss:0.01121\teval-logloss:0.14020\n",
      "[91]\ttrain-logloss:0.01108\teval-logloss:0.14020\n",
      "[92]\ttrain-logloss:0.01095\teval-logloss:0.14122\n",
      "[93]\ttrain-logloss:0.01081\teval-logloss:0.14160\n",
      "[94]\ttrain-logloss:0.01068\teval-logloss:0.14150\n",
      "[95]\ttrain-logloss:0.01059\teval-logloss:0.14195\n",
      "[96]\ttrain-logloss:0.01046\teval-logloss:0.14260\n",
      "[97]\ttrain-logloss:0.01035\teval-logloss:0.14220\n",
      "[98]\ttrain-logloss:0.01026\teval-logloss:0.14248\n",
      "[99]\ttrain-logloss:0.01014\teval-logloss:0.14241\n",
      "[100]\ttrain-logloss:0.01004\teval-logloss:0.14292\n",
      "[101]\ttrain-logloss:0.00997\teval-logloss:0.14307\n",
      "[102]\ttrain-logloss:0.00986\teval-logloss:0.14301\n",
      "[103]\ttrain-logloss:0.00975\teval-logloss:0.14259\n",
      "[104]\ttrain-logloss:0.00967\teval-logloss:0.14300\n",
      "[105]\ttrain-logloss:0.00960\teval-logloss:0.14350\n",
      "[106]\ttrain-logloss:0.00951\teval-logloss:0.14346\n",
      "[107]\ttrain-logloss:0.00946\teval-logloss:0.14335\n",
      "[108]\ttrain-logloss:0.00938\teval-logloss:0.14382\n",
      "[109]\ttrain-logloss:0.00927\teval-logloss:0.14341\n",
      "[110]\ttrain-logloss:0.00923\teval-logloss:0.14373\n",
      "[111]\ttrain-logloss:0.00914\teval-logloss:0.14371\n",
      "[112]\ttrain-logloss:0.00908\teval-logloss:0.14376\n",
      "[113]\ttrain-logloss:0.00900\teval-logloss:0.14393\n",
      "[114]\ttrain-logloss:0.00891\teval-logloss:0.14362\n",
      "[115]\ttrain-logloss:0.00887\teval-logloss:0.14350\n",
      "[116]\ttrain-logloss:0.00879\teval-logloss:0.14402\n",
      "[117]\ttrain-logloss:0.00875\teval-logloss:0.14432\n",
      "[118]\ttrain-logloss:0.00868\teval-logloss:0.14432\n",
      "[119]\ttrain-logloss:0.00864\teval-logloss:0.14421\n",
      "[120]\ttrain-logloss:0.00858\teval-logloss:0.14496\n",
      "[121]\ttrain-logloss:0.00850\teval-logloss:0.14543\n",
      "[122]\ttrain-logloss:0.00844\teval-logloss:0.14511\n",
      "[123]\ttrain-logloss:0.00841\teval-logloss:0.14544\n",
      "[124]\ttrain-logloss:0.00833\teval-logloss:0.14529\n",
      "[125]\ttrain-logloss:0.00830\teval-logloss:0.14519\n",
      "[126]\ttrain-logloss:0.00821\teval-logloss:0.14525\n",
      "[127]\ttrain-logloss:0.00818\teval-logloss:0.14554\n",
      "[128]\ttrain-logloss:0.00812\teval-logloss:0.14555\n",
      "[129]\ttrain-logloss:0.00809\teval-logloss:0.14545\n",
      "[130]\ttrain-logloss:0.00806\teval-logloss:0.14577\n",
      "[131]\ttrain-logloss:0.00803\teval-logloss:0.14614\n",
      "[132]\ttrain-logloss:0.00800\teval-logloss:0.14603\n",
      "[133]\ttrain-logloss:0.00797\teval-logloss:0.14648\n",
      "[134]\ttrain-logloss:0.00791\teval-logloss:0.14650\n",
      "[135]\ttrain-logloss:0.00788\teval-logloss:0.14681\n",
      "[136]\ttrain-logloss:0.00786\teval-logloss:0.14671\n",
      "[137]\ttrain-logloss:0.00783\teval-logloss:0.14697\n",
      "[138]\ttrain-logloss:0.00776\teval-logloss:0.14741\n",
      "[139]\ttrain-logloss:0.00773\teval-logloss:0.14728\n",
      "[140]\ttrain-logloss:0.00769\teval-logloss:0.14726\n",
      "[141]\ttrain-logloss:0.00766\teval-logloss:0.14752\n",
      "[142]\ttrain-logloss:0.00760\teval-logloss:0.14794\n",
      "[143]\ttrain-logloss:0.00758\teval-logloss:0.14820\n",
      "[144]\ttrain-logloss:0.00755\teval-logloss:0.14833\n",
      "[145]\ttrain-logloss:0.00753\teval-logloss:0.14823\n",
      "[146]\ttrain-logloss:0.00750\teval-logloss:0.14812\n",
      "[147]\ttrain-logloss:0.00746\teval-logloss:0.14831\n",
      "[148]\ttrain-logloss:0.00743\teval-logloss:0.14861\n",
      "[149]\ttrain-logloss:0.00741\teval-logloss:0.14838\n",
      "[150]\ttrain-logloss:0.00739\teval-logloss:0.14850\n",
      "[151]\ttrain-logloss:0.00737\teval-logloss:0.14875\n",
      "[152]\ttrain-logloss:0.00734\teval-logloss:0.14893\n",
      "[153]\ttrain-logloss:0.00732\teval-logloss:0.14876\n",
      "[154]\ttrain-logloss:0.00730\teval-logloss:0.14867\n",
      "[155]\ttrain-logloss:0.00728\teval-logloss:0.14907\n",
      "[156]\ttrain-logloss:0.00726\teval-logloss:0.14936\n",
      "[157]\ttrain-logloss:0.00724\teval-logloss:0.14947\n",
      "[158]\ttrain-logloss:0.00722\teval-logloss:0.14926\n",
      "[159]\ttrain-logloss:0.00719\teval-logloss:0.14916\n",
      "[160]\ttrain-logloss:0.00717\teval-logloss:0.14932\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[161]\ttrain-logloss:0.00715\teval-logloss:0.14957\n",
      "[162]\ttrain-logloss:0.00713\teval-logloss:0.14989\n",
      "[163]\ttrain-logloss:0.00711\teval-logloss:0.15005\n",
      "[164]\ttrain-logloss:0.00709\teval-logloss:0.14994\n",
      "[165]\ttrain-logloss:0.00707\teval-logloss:0.14997\n",
      "[166]\ttrain-logloss:0.00705\teval-logloss:0.14989\n",
      "[167]\ttrain-logloss:0.00703\teval-logloss:0.15026\n",
      "[168]\ttrain-logloss:0.00701\teval-logloss:0.15011\n",
      "[169]\ttrain-logloss:0.00700\teval-logloss:0.14990\n",
      "[170]\ttrain-logloss:0.00698\teval-logloss:0.15002\n",
      "[171]\ttrain-logloss:0.00696\teval-logloss:0.15037\n",
      "[172]\ttrain-logloss:0.00694\teval-logloss:0.15023\n",
      "[173]\ttrain-logloss:0.00692\teval-logloss:0.15038\n",
      "[174]\ttrain-logloss:0.00690\teval-logloss:0.15068\n",
      "[175]\ttrain-logloss:0.00688\teval-logloss:0.15060\n",
      "[176]\ttrain-logloss:0.00687\teval-logloss:0.15086\n",
      "[177]\ttrain-logloss:0.00685\teval-logloss:0.15097\n",
      "[178]\ttrain-logloss:0.00683\teval-logloss:0.15088\n",
      "[179]\ttrain-logloss:0.00681\teval-logloss:0.15111\n",
      "[180]\ttrain-logloss:0.00680\teval-logloss:0.15103\n",
      "[181]\ttrain-logloss:0.00678\teval-logloss:0.15108\n",
      "[182]\ttrain-logloss:0.00676\teval-logloss:0.15142\n",
      "[183]\ttrain-logloss:0.00675\teval-logloss:0.15128\n",
      "[184]\ttrain-logloss:0.00673\teval-logloss:0.15121\n",
      "[185]\ttrain-logloss:0.00671\teval-logloss:0.15159\n",
      "[186]\ttrain-logloss:0.00670\teval-logloss:0.15144\n",
      "[187]\ttrain-logloss:0.00668\teval-logloss:0.15180\n",
      "[188]\ttrain-logloss:0.00666\teval-logloss:0.15205\n",
      "[189]\ttrain-logloss:0.00665\teval-logloss:0.15198\n",
      "[190]\ttrain-logloss:0.00663\teval-logloss:0.15190\n",
      "[191]\ttrain-logloss:0.00662\teval-logloss:0.15223\n",
      "[192]\ttrain-logloss:0.00660\teval-logloss:0.15259\n",
      "[193]\ttrain-logloss:0.00659\teval-logloss:0.15214\n",
      "[194]\ttrain-logloss:0.00657\teval-logloss:0.15216\n",
      "[195]\ttrain-logloss:0.00656\teval-logloss:0.15253\n",
      "[196]\ttrain-logloss:0.00654\teval-logloss:0.15238\n",
      "[197]\ttrain-logloss:0.00653\teval-logloss:0.15231\n",
      "[198]\ttrain-logloss:0.00651\teval-logloss:0.15224\n",
      "[199]\ttrain-logloss:0.00650\teval-logloss:0.15260\n",
      "[200]\ttrain-logloss:0.00648\teval-logloss:0.15215\n",
      "[201]\ttrain-logloss:0.00647\teval-logloss:0.15238\n",
      "[202]\ttrain-logloss:0.00646\teval-logloss:0.15251\n",
      "[203]\ttrain-logloss:0.00644\teval-logloss:0.15286\n",
      "[204]\ttrain-logloss:0.00643\teval-logloss:0.15279\n",
      "[205]\ttrain-logloss:0.00641\teval-logloss:0.15268\n",
      "[206]\ttrain-logloss:0.00640\teval-logloss:0.15270\n",
      "[207]\ttrain-logloss:0.00639\teval-logloss:0.15246\n",
      "[208]\ttrain-logloss:0.00637\teval-logloss:0.15274\n",
      "[209]\ttrain-logloss:0.00636\teval-logloss:0.15287\n",
      "[210]\ttrain-logloss:0.00635\teval-logloss:0.15309\n",
      "[211]\ttrain-logloss:0.00633\teval-logloss:0.15302\n",
      "[212]\ttrain-logloss:0.00632\teval-logloss:0.15296\n",
      "[213]\ttrain-logloss:0.00630\teval-logloss:0.15332\n",
      "[214]\ttrain-logloss:0.00629\teval-logloss:0.15308\n",
      "[215]\ttrain-logloss:0.00628\teval-logloss:0.15335\n",
      "[216]\ttrain-logloss:0.00627\teval-logloss:0.15348\n",
      "[217]\ttrain-logloss:0.00625\teval-logloss:0.15351\n",
      "[218]\ttrain-logloss:0.00624\teval-logloss:0.15340\n",
      "[219]\ttrain-logloss:0.00623\teval-logloss:0.15334\n",
      "[220]\ttrain-logloss:0.00621\teval-logloss:0.15368\n",
      "[221]\ttrain-logloss:0.00620\teval-logloss:0.15345\n",
      "[222]\ttrain-logloss:0.00619\teval-logloss:0.15348\n",
      "[223]\ttrain-logloss:0.00618\teval-logloss:0.15361\n",
      "[224]\ttrain-logloss:0.00617\teval-logloss:0.15387\n",
      "[225]\ttrain-logloss:0.00615\teval-logloss:0.15381\n",
      "[226]\ttrain-logloss:0.00614\teval-logloss:0.15403\n",
      "[227]\ttrain-logloss:0.00613\teval-logloss:0.15436\n",
      "[228]\ttrain-logloss:0.00612\teval-logloss:0.15414\n",
      "[229]\ttrain-logloss:0.00611\teval-logloss:0.15435\n",
      "[230]\ttrain-logloss:0.00609\teval-logloss:0.15448\n",
      "[231]\ttrain-logloss:0.00608\teval-logloss:0.15474\n",
      "[232]\ttrain-logloss:0.00607\teval-logloss:0.15468\n",
      "[233]\ttrain-logloss:0.00606\teval-logloss:0.15471\n",
      "[234]\ttrain-logloss:0.00605\teval-logloss:0.15448\n",
      "[235]\ttrain-logloss:0.00604\teval-logloss:0.15482\n",
      "[236]\ttrain-logloss:0.00603\teval-logloss:0.15461\n",
      "[237]\ttrain-logloss:0.00601\teval-logloss:0.15493\n",
      "[238]\ttrain-logloss:0.00600\teval-logloss:0.15470\n",
      "[239]\ttrain-logloss:0.00599\teval-logloss:0.15491\n",
      "[240]\ttrain-logloss:0.00598\teval-logloss:0.15524\n",
      "[241]\ttrain-logloss:0.00597\teval-logloss:0.15537\n",
      "[242]\ttrain-logloss:0.00596\teval-logloss:0.15530\n",
      "[243]\ttrain-logloss:0.00595\teval-logloss:0.15525\n",
      "[244]\ttrain-logloss:0.00594\teval-logloss:0.15528\n",
      "[245]\ttrain-logloss:0.00593\teval-logloss:0.15554\n",
      "[246]\ttrain-logloss:0.00592\teval-logloss:0.15532\n",
      "[247]\ttrain-logloss:0.00591\teval-logloss:0.15552\n",
      "[248]\ttrain-logloss:0.00590\teval-logloss:0.15578\n",
      "[249]\ttrain-logloss:0.00589\teval-logloss:0.15590\n",
      "[250]\ttrain-logloss:0.00587\teval-logloss:0.15611\n",
      "[251]\ttrain-logloss:0.00586\teval-logloss:0.15605\n",
      "[252]\ttrain-logloss:0.00585\teval-logloss:0.15640\n",
      "[253]\ttrain-logloss:0.00584\teval-logloss:0.15617\n",
      "[254]\ttrain-logloss:0.00583\teval-logloss:0.15649\n",
      "[255]\ttrain-logloss:0.00582\teval-logloss:0.15628\n",
      "[256]\ttrain-logloss:0.00581\teval-logloss:0.15611\n",
      "[257]\ttrain-logloss:0.00580\teval-logloss:0.15636\n",
      "[258]\ttrain-logloss:0.00579\teval-logloss:0.15613\n",
      "[259]\ttrain-logloss:0.00579\teval-logloss:0.15632\n",
      "[260]\ttrain-logloss:0.00578\teval-logloss:0.15621\n",
      "[261]\ttrain-logloss:0.00577\teval-logloss:0.15652\n",
      "[262]\ttrain-logloss:0.00576\teval-logloss:0.15647\n",
      "[263]\ttrain-logloss:0.00575\teval-logloss:0.15666\n",
      "[264]\ttrain-logloss:0.00574\teval-logloss:0.15701\n",
      "[265]\ttrain-logloss:0.00573\teval-logloss:0.15679\n",
      "[266]\ttrain-logloss:0.00572\teval-logloss:0.15703\n",
      "[267]\ttrain-logloss:0.00571\teval-logloss:0.15683\n",
      "[268]\ttrain-logloss:0.00570\teval-logloss:0.15702\n",
      "[269]\ttrain-logloss:0.00569\teval-logloss:0.15697\n",
      "[270]\ttrain-logloss:0.00568\teval-logloss:0.15708\n",
      "[271]\ttrain-logloss:0.00567\teval-logloss:0.15733\n",
      "[272]\ttrain-logloss:0.00566\teval-logloss:0.15752\n",
      "[273]\ttrain-logloss:0.00566\teval-logloss:0.15752\n",
      "[274]\ttrain-logloss:0.00565\teval-logloss:0.15730\n",
      "[275]\ttrain-logloss:0.00564\teval-logloss:0.15714\n",
      "[276]\ttrain-logloss:0.00563\teval-logloss:0.15745\n",
      "[277]\ttrain-logloss:0.00562\teval-logloss:0.15726\n",
      "[278]\ttrain-logloss:0.00561\teval-logloss:0.15744\n",
      "[279]\ttrain-logloss:0.00560\teval-logloss:0.15733\n",
      "[280]\ttrain-logloss:0.00559\teval-logloss:0.15734\n",
      "[281]\ttrain-logloss:0.00559\teval-logloss:0.15728\n",
      "[282]\ttrain-logloss:0.00558\teval-logloss:0.15752\n",
      "[283]\ttrain-logloss:0.00557\teval-logloss:0.15739\n",
      "[284]\ttrain-logloss:0.00556\teval-logloss:0.15757\n",
      "[285]\ttrain-logloss:0.00555\teval-logloss:0.15739\n",
      "[286]\ttrain-logloss:0.00554\teval-logloss:0.15762\n",
      "[287]\ttrain-logloss:0.00554\teval-logloss:0.15747\n",
      "[288]\ttrain-logloss:0.00553\teval-logloss:0.15740\n",
      "[289]\ttrain-logloss:0.00552\teval-logloss:0.15719\n",
      "[290]\ttrain-logloss:0.00551\teval-logloss:0.15749\n",
      "[291]\ttrain-logloss:0.00550\teval-logloss:0.15767\n",
      "[292]\ttrain-logloss:0.00549\teval-logloss:0.15757\n",
      "[293]\ttrain-logloss:0.00549\teval-logloss:0.15739\n",
      "[294]\ttrain-logloss:0.00548\teval-logloss:0.15744\n",
      "[295]\ttrain-logloss:0.00547\teval-logloss:0.15762\n",
      "[296]\ttrain-logloss:0.00546\teval-logloss:0.15758\n",
      "[297]\ttrain-logloss:0.00545\teval-logloss:0.15751\n",
      "[298]\ttrain-logloss:0.00545\teval-logloss:0.15769\n",
      "[299]\ttrain-logloss:0.00544\teval-logloss:0.15793\n"
     ]
    }
   ],
   "source": [
    "#help(xgboost.DMatrix)\n",
    "dtrain = xgboost.DMatrix(data = Xtrain, label = ytrain)\n",
    "dtest = xgboost.DMatrix(data = Xtest, label = ytest)\n",
    "params =  {'max_depth' : 3,\n",
    "         'eta' : 0.1, \n",
    "         'objective' : 'binary:logistic',\n",
    "         'eval_metric' : 'logloss',\n",
    "         'early_stoppings' : 100 }\n",
    "model = xgboost.train(params = params, dtrain = dtrain, evals = [(dtrain, 'train'), (dtest, 'eval')],\n",
    "                     num_boost_round = 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "preliminary-haiti",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.predict(dtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "desirable-hacker",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = [1 if i >0.5 else 0 for i in preds]\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "worthy-wealth",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.043859649122807015"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(abs(ytest-result))/len(ytest)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "duplicate-jamaica",
   "metadata": {},
   "source": [
    "#  빅분기 작업형 2유형 기출 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "focal-pharmacology",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cust_id</th>\n",
       "      <th>total_buy</th>\n",
       "      <th>max_buy</th>\n",
       "      <th>payback</th>\n",
       "      <th>main_product</th>\n",
       "      <th>where</th>\n",
       "      <th>days</th>\n",
       "      <th>buy_per_day</th>\n",
       "      <th>weekend_come</th>\n",
       "      <th>buy_period</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3500</td>\n",
       "      <td>70900400</td>\n",
       "      <td>22000000</td>\n",
       "      <td>4050000.0</td>\n",
       "      <td>골프</td>\n",
       "      <td>부산본점</td>\n",
       "      <td>13</td>\n",
       "      <td>1.461538</td>\n",
       "      <td>0.789474</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3501</td>\n",
       "      <td>310533100</td>\n",
       "      <td>38558000</td>\n",
       "      <td>48034700.0</td>\n",
       "      <td>농산물</td>\n",
       "      <td>잠실점</td>\n",
       "      <td>90</td>\n",
       "      <td>2.433333</td>\n",
       "      <td>0.369863</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3502</td>\n",
       "      <td>305264140</td>\n",
       "      <td>14825000</td>\n",
       "      <td>30521000.0</td>\n",
       "      <td>가공식품</td>\n",
       "      <td>본  점</td>\n",
       "      <td>101</td>\n",
       "      <td>14.623762</td>\n",
       "      <td>0.083277</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3503</td>\n",
       "      <td>7594080</td>\n",
       "      <td>5225000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>주방용품</td>\n",
       "      <td>부산본점</td>\n",
       "      <td>5</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3504</td>\n",
       "      <td>1795790</td>\n",
       "      <td>1411200</td>\n",
       "      <td>NaN</td>\n",
       "      <td>수산품</td>\n",
       "      <td>청량리점</td>\n",
       "      <td>3</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2477</th>\n",
       "      <td>5977</td>\n",
       "      <td>82581500</td>\n",
       "      <td>23976000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>골프</td>\n",
       "      <td>부산본점</td>\n",
       "      <td>8</td>\n",
       "      <td>1.750000</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2478</th>\n",
       "      <td>5978</td>\n",
       "      <td>480000</td>\n",
       "      <td>480000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>섬유잡화</td>\n",
       "      <td>광주점</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2479</th>\n",
       "      <td>5979</td>\n",
       "      <td>260003790</td>\n",
       "      <td>25750000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>남성 캐주얼</td>\n",
       "      <td>본  점</td>\n",
       "      <td>19</td>\n",
       "      <td>3.736842</td>\n",
       "      <td>0.915493</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2480</th>\n",
       "      <td>5980</td>\n",
       "      <td>88991520</td>\n",
       "      <td>18120000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>육류</td>\n",
       "      <td>본  점</td>\n",
       "      <td>5</td>\n",
       "      <td>3.600000</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2481</th>\n",
       "      <td>5981</td>\n",
       "      <td>623700</td>\n",
       "      <td>209000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>가공식품</td>\n",
       "      <td>영등포점</td>\n",
       "      <td>2</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2482 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      cust_id  total_buy   max_buy     payback main_product where  days  \\\n",
       "0        3500   70900400  22000000   4050000.0           골프  부산본점    13   \n",
       "1        3501  310533100  38558000  48034700.0          농산물   잠실점    90   \n",
       "2        3502  305264140  14825000  30521000.0         가공식품  본  점   101   \n",
       "3        3503    7594080   5225000         NaN         주방용품  부산본점     5   \n",
       "4        3504    1795790   1411200         NaN          수산품  청량리점     3   \n",
       "...       ...        ...       ...         ...          ...   ...   ...   \n",
       "2477     5977   82581500  23976000         NaN           골프  부산본점     8   \n",
       "2478     5978     480000    480000         NaN         섬유잡화   광주점     1   \n",
       "2479     5979  260003790  25750000         NaN       남성 캐주얼  본  점    19   \n",
       "2480     5980   88991520  18120000         NaN           육류  본  점     5   \n",
       "2481     5981     623700    209000         NaN         가공식품  영등포점     2   \n",
       "\n",
       "      buy_per_day  weekend_come  buy_period  \n",
       "0        1.461538      0.789474          26  \n",
       "1        2.433333      0.369863           3  \n",
       "2       14.623762      0.083277           3  \n",
       "3        2.000000      0.000000          47  \n",
       "4        2.666667      0.125000           8  \n",
       "...           ...           ...         ...  \n",
       "2477     1.750000      0.642857          40  \n",
       "2478     1.000000      0.000000           0  \n",
       "2479     3.736842      0.915493          18  \n",
       "2480     3.600000      0.444444          60  \n",
       "2481     5.000000      0.000000          31  \n",
       "\n",
       "[2482 rows x 10 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "path = 'C:/Users/100do/python/승혜/archive/'\n",
    "ytrain = pd.read_csv(path + 'y_train.csv')\n",
    "xtrain = pd.read_csv(path + 'X_train_2.csv' )\n",
    "xtest = pd.read_csv(path + 'X_test_2.csv')\n",
    "xtest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "embedded-harvard",
   "metadata": {},
   "source": [
    "1. 숫자형, text, 변수 분리 -> get_dummies to text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ancient-library",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3500 entries, 0 to 3499\n",
      "Data columns (total 10 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   cust_id       3500 non-null   int64  \n",
      " 1   total_buy     3500 non-null   int64  \n",
      " 2   max_buy       3500 non-null   int64  \n",
      " 3   payback       1205 non-null   float64\n",
      " 4   main_product  3500 non-null   object \n",
      " 5   where         3500 non-null   object \n",
      " 6   days          3500 non-null   int64  \n",
      " 7   buy_per_day   3500 non-null   float64\n",
      " 8   weekend_come  3500 non-null   float64\n",
      " 9   buy_period    3500 non-null   int64  \n",
      "dtypes: float64(3), int64(5), object(2)\n",
      "memory usage: 273.6+ KB\n"
     ]
    }
   ],
   "source": [
    "xtrain.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "intellectual-shadow",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_str = xtrain[['main_product', 'where']]\n",
    "x_num = xtrain[['total_buy','max_buy','payback','days','buy_per_day','weekend_come','buy_period']]\n",
    "xtest_str = xtest[['main_product', 'where']]\n",
    "xtest_num = xtest[['total_buy','max_buy','payback','days','buy_per_day','weekend_come','buy_period']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "polished-royal",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   main_product_가공식품  main_product_가구  main_product_건강식품  main_product_골프  \\\n",
      "0                  0                0                  0                1   \n",
      "1                  0                0                  0                0   \n",
      "2                  1                0                  0                0   \n",
      "3                  0                0                  0                0   \n",
      "4                  0                0                  0                0   \n",
      "\n",
      "   main_product_구두  main_product_기타  main_product_남성 캐주얼  main_product_남성 트랜디  \\\n",
      "0                0                0                    0                    0   \n",
      "1                0                0                    0                    0   \n",
      "2                0                0                    0                    0   \n",
      "3                0                0                    0                    0   \n",
      "4                0                0                    0                    0   \n",
      "\n",
      "   main_product_남성정장  main_product_농산물  ...  where_안양점  where_영등포점  where_울산점  \\\n",
      "0                  0                 0  ...          0           0          0   \n",
      "1                  0                 1  ...          0           0          0   \n",
      "2                  0                 0  ...          0           0          0   \n",
      "3                  0                 0  ...          0           0          0   \n",
      "4                  0                 0  ...          0           0          0   \n",
      "\n",
      "   where_인천점  where_일산점  where_잠실점  where_전주점  where_창원점  where_청량리점  \\\n",
      "0          0          0          0          0          0           0   \n",
      "1          0          0          1          0          0           0   \n",
      "2          0          0          0          0          0           0   \n",
      "3          0          0          0          0          0           0   \n",
      "4          0          0          0          0          0           1   \n",
      "\n",
      "   where_포항점  \n",
      "0          0  \n",
      "1          0  \n",
      "2          0  \n",
      "3          0  \n",
      "4          0  \n",
      "\n",
      "[5 rows x 65 columns]\n",
      "65\n"
     ]
    }
   ],
   "source": [
    "x_str = pd.get_dummies(x_str)\n",
    "xtest_str = pd.get_dummies(xtest_str)\n",
    "print(xtest_str.head())\n",
    "print(len(xtest_str.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "olympic-passing",
   "metadata": {},
   "source": [
    "2. xtest_str, x_str get dummies 한 컬럼 맞추기 위해 concat 진행\n",
    " - align 사용\n",
    " - align 사용할 때 inner 하면 두데이터 동시에 같는 인덱스만 출력한다.\n",
    " - test, train 클래스 개수 맞춰줄 때만 원 핫 인코딩 사용 가능함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "genuine-tuition",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "65"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_str, xtest_str = x_str.align(xtest_str, join = 'inner', axis = 1)\n",
    "len(xtest_str.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "committed-renewal",
   "metadata": {},
   "source": [
    "3. 수치형 데이터에서 결측치 제거. <br>\n",
    " - 결측치 제거 후 개수 많이 작아진거 아니면 mean으로 대체\n",
    " - 이상체를 상한, 하한 임계치 수치로 변환\n",
    " - drop 해도 인덱스가 그대로 있으니까 str이랑 맞추는거 가능할 거라 생각함\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "derived-heater",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total_buy</th>\n",
       "      <th>max_buy</th>\n",
       "      <th>payback</th>\n",
       "      <th>days</th>\n",
       "      <th>buy_per_day</th>\n",
       "      <th>weekend_come</th>\n",
       "      <th>buy_period</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>68282840.0</td>\n",
       "      <td>11264000.0</td>\n",
       "      <td>6605625.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>3.894737</td>\n",
       "      <td>0.527027</td>\n",
       "      <td>17.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2136000.0</td>\n",
       "      <td>2136000.0</td>\n",
       "      <td>300000.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3197000.0</td>\n",
       "      <td>1639000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16077620.0</td>\n",
       "      <td>4935000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.444444</td>\n",
       "      <td>0.318182</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>29050000.0</td>\n",
       "      <td>24000000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>64.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3495</th>\n",
       "      <td>3175200.0</td>\n",
       "      <td>3042900.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3496</th>\n",
       "      <td>29628600.0</td>\n",
       "      <td>7200000.0</td>\n",
       "      <td>6049600.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.625000</td>\n",
       "      <td>0.461538</td>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3497</th>\n",
       "      <td>75000.0</td>\n",
       "      <td>75000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3498</th>\n",
       "      <td>1875000.0</td>\n",
       "      <td>1000000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>39.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3499</th>\n",
       "      <td>259149250.0</td>\n",
       "      <td>34632000.0</td>\n",
       "      <td>5973000.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>2.421053</td>\n",
       "      <td>0.467391</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3500 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        total_buy     max_buy    payback  days  buy_per_day  weekend_come  \\\n",
       "0      68282840.0  11264000.0  6605625.0  19.0     3.894737      0.527027   \n",
       "1       2136000.0   2136000.0   300000.0   2.0     1.500000      0.000000   \n",
       "2       3197000.0   1639000.0        0.0   2.0     2.000000      0.000000   \n",
       "3      16077620.0   4935000.0        0.0  18.0     2.444444      0.318182   \n",
       "4      29050000.0  24000000.0        0.0   2.0     1.500000      0.000000   \n",
       "...           ...         ...        ...   ...          ...           ...   \n",
       "3495    3175200.0   3042900.0        0.0   1.0     2.000000      1.000000   \n",
       "3496   29628600.0   7200000.0  6049600.0   8.0     1.625000      0.461538   \n",
       "3497      75000.0     75000.0        0.0   1.0     1.000000      0.000000   \n",
       "3498    1875000.0   1000000.0        0.0   2.0     1.000000      0.000000   \n",
       "3499  259149250.0  34632000.0  5973000.0  38.0     2.421053      0.467391   \n",
       "\n",
       "      buy_period  \n",
       "0           17.0  \n",
       "1            1.0  \n",
       "2            1.0  \n",
       "3           16.0  \n",
       "4           64.0  \n",
       "...          ...  \n",
       "3495         0.0  \n",
       "3496        40.0  \n",
       "3497         0.0  \n",
       "3498        39.0  \n",
       "3499         8.0  \n",
       "\n",
       "[3500 rows x 7 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# payback이 na인거는 환불 안한거라는 뜻이니까 0으로 바꾸자.\n",
    "x_num = x_num.fillna(0)\n",
    "q3 = x_num.quantile(q = 0.75)\n",
    "q1 = x_num.quantile(q = 0.25)\n",
    "iqr = q3-q1\n",
    "upper = q3 + iqr*1.5\n",
    "lower = q1 - iqr*1.5 # 다 음수니까 아래는 안빼도 될듯\n",
    "x_num_rm = x_num[ x_num < upper ]\n",
    "x_num_rm = x_num_rm.fillna(upper)\n",
    "x_num_rm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "spanish-width",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x_num_str' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-34-492e496297a4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mx_num_str\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'x_num_str' is not defined"
     ]
    }
   ],
   "source": [
    "practice this -> # https://hobby-weighted.tistory.com/157   "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
